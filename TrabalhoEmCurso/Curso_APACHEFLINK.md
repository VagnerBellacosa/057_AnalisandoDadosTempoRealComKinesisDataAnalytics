## APACHE FLINK

# Treinamento Apache Flink com Scala



[![Treinamento Apache Flink com Scala](https://www.ambientelivre.com.br/media/k2/items/cache/35b3ab2a19f46ac3056fff8ccff085c4_L.jpg)](https://www.ambientelivre.com.br/media/k2/items/cache/35b3ab2a19f46ac3056fff8ccff085c4_XL.jpg)

### SOBRE O TREINAMENTO

O treinamento **Apache Flink** e voltado para profissionais de big data e ciência de dados qua atuam com administração de clusters com Apache Flink implantado mas principalmente para desenvolvedores para que possam após o treinamento ser capaz de construir aplicações de Big Data usando uma das tecnologias mais modernas para processamento massivo o Flink, são abordados conhecimentos de arquitetura e ecossistemas fundamentais para a programação com a **linguagem Scala** e o **Framework de código aberto Apache Flink**. Entender os principais conceitos e fluxo de trabalho de implementação, dominar tópicos avançados de manipulação de RDDs, saber escrever scripts Flink com acesso a HDFS, Hive, HBase e interações com outros projetos do ecossistema Hadoop necessários para a análise de dados. Saber fazer uso de motores de processamento e desenvolver soluções que utilizam componentes em todo hub de dados da empresa. Ser capaz de construir aplicativos usando Apache Flink para processamento de stream combinando dados históricos com dados de streaming, através de análises interativas em tempo real.

####  Turmas Somente inCompany

 

### CONTEÚDO PROGRAMÁTICO

#### Conceitual Big Data e Spark

- Visão geral sobre Hadoop.
- Características do Hadoop.
- Sistema distribuído de arquivos.
- Ecossistema Hadoop.
- Quem usa o Hadoop.
- Cases do uso Hadoop.
- Uso de Hadware comum.
- Distribuições do Hadoop (Cloudera X Hortonworks X Apache).
- Apache Flink X Apache Spark.
- Histórico do Apache Flink.
- Casos de uso de Flink.
- Empresas usando Flink no Mundo.
- Empresas usando Flink no Brasil.

#### Introdução a Linguagem Scala

- A Linguagem Scala.
- Linguagens JVMs.
- Instalando Scala.
- Journey - Java para Scala
- First Dive - Interactive Scala.
- Escrevendo scripts Scala.
- Compilando Programas Scala.
- Basico em Scala.
- Tipos Básicos Scala.
- Definindo Funções.
- IDE para Scala.
- Scala Community.

#### Essencial em Scala

- Imutabilidade em Scala - Semicolons.
- Declaração método.
- Literais.
- Listas.
- Tuplas.
- Opções.
- Maps.
- Palavras reservadas.
- Operadores.
- Regras de precedência.
- If Statements.
- Scala para Compreensão.
- While Loops, Do-While Loops.
- Operadores condicionais.
- Pattern Matching.
- Enumerações.

#### Traits e OOPs em Scala

- Traits Intro - Traits as Mixins.
- Stackable Traits.
- Criando Traits e OOPS - Classes and Objetos Básicos.
- Construtores Scala.
- Nested Classes.
- Visibility Rules.

#### Programação Funcional em Scala.

- O que é programação funcional?
- Literais funcionais e Closures.
- Recursão.
- Tail Calls.
- Estruturas de Dados Funcionais.
- Parâmetros das Funções implícitas.
- Chamada por nome.
- Chamada por Valor.

#### Instalação do Apache Flink.

- Visão geral da arquitetura Flink.
- Instalando o Apache Flink.
- Modos do Flink.
- Standalone Cluster.
- Multi-Node Flink Cluster.
- Gerenciamento de memória.

#### Desenvolvendo com Apache Flink.

- Invocando Scala REPL.
- Criando o Contexto Spark.
- Carregando um arquivo no Scala REPL.
- Realizando algumas operações básicas em arquivos em Scala REPL.
- Paralelo Stream.

#### Flink DataStream API - Streaming.

- Event Time.
- Estado e Tolerância a falha.
- Operadores.
- Conectores.
- Window SQL.

#### Flink DataSet API - **Batch**.

- Transformações.
- Interações.
- Conectores.
- Execução Local.
- Execução em Cluster.
- Zipping.
- Compatibilidade com Hadoop.

#### Flink Table SQL API e Hive

- Arquitetura Table SQL.
- Data Type.
- Table API.
- SQL e SQL Client.
- UDFs.
- Data Sinks.
- Catalogos.
- Window Table SQL.
- Integrando com Hive.

#### Recursos gerais

- CEP.
- Melhores práticas.

#### Apache Flink e Pentaho.

- Overview Suite Pentaho.
- Pentaho data Integration e AEL - Adaptative Execution Layer.
- Data Visualization.

### CARGA HORÁRIA:

- 32 Horas.

### PRÉ-REQUISITOS DOS PARTICIPANTES:

- Conhecimento em Programação Java ou alguma linguagem com Orientação Objeto.
- Noções de Big Data.
- Conhecimento de Banco de Dados e SQL.
- Conhecimento Básico de Linux.
- Todos os participantes devem trazer um notebook para realizar as atividades práticas.
- O Computador deve estar com acesso de administrador para possibilitar instalações de aplicativos e acesso a Internet.
- Para turmas In-Company não trabalhamos com limite de participantes para os treinamentos, orientamos que as turmas sejam de até 12 alunos para um melhor desempenho.

### REQUISITOS MÍNIMOS DE HARDWARE:

- Memória RAM : 8 GB.
- Espaço em Disco: 20GB.
- Processador: Dual-core AMD 64, EM64T
- deve estar ativo a Virtualização na BIOS do equipamento.
- Sistemas Operacionais:Qualquer um com suporte e Virtualização com VirtualBox.
- Oracle VM VirtualBox ( https://www.virtualbox.org/ ).
- **Obs. Equipamentos com menos que 8GB de Memória RAM (Entre 5GB e 8GB) podem passar por lentidão nas atividades de uso de maquinas virtuais simultâneas no treinamento. Equipamentos com 4GB ou inferior não funcionarão para o treinamento.**

### MATERIAL

Serão disponibilizados os seguintes materiais aos alunos do treinamento:

- Todos os softwares Apache Flink e Scala e acessórios na sua última versão estável.
- Material próprio em Português do Brasil.
- Apresentações ( slides do treinamento ) desenvolvidas pela equipe Ambiente Livre.
- Apostilas digitais dos softwares desenvolvidas pela Ambiente Livre.
- Apostilas com exercícios práticos desenvolvidos no treinamento.
- Materiais e documentações complementares desenvolvido pela Comunidade Open Source Mundial.
- Caneta, Pasta e Bloco de Anotações.

### METODOLOGIA

- Todos os dias serão apresentados novos recursos e conceitos e avaliados através de exercícios práticos em todas as aulas